variables:
  - &e2e_include_expansions_in_env
    include_expansions_in_env:
      - ecr_registry
      - ecr_registry_needs_auth
      - openshift_url
      - openshift_token
      - workdir
      - mms_eng_test_aws_access_key
      - mms_eng_test_aws_secret
      - mms_eng_test_aws_region
      - OVERRIDE_VERSION_ID
      - version_id
      - task_name
      - e2e_cloud_qa_user_owner_ubi_cloudqa
      - e2e_cloud_qa_apikey_owner_ubi_cloudqa
      - e2e_cloud_qa_orgid_owner_ubi_cloudqa
      - otel_trace_id
      - otel_parent_id
      - otel_collector_endpoint
      - branch_name
      - requester
      - is_patch
      - github_commit
      - build_variant
      - execution
      - build_id

functions:

  ### Setup Functions ###

  setup_context: &setup_context # Running the first switch is important to fill the workdir and other important initial env vars
    command: shell.exec
    type: setup
    params:
      shell: bash
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      <<: *e2e_include_expansions_in_env
      script: |
        echo "Initializing context files"
        cp scripts/dev/contexts/evg-private-context scripts/dev/contexts/private-context
        scripts/dev/switch_context.sh root-context
        echo "Finished initializing to the root context"

  switch_context: &switch_context
    command: shell.exec
    type: setup
    params:
      shell: bash
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      <<: *e2e_include_expansions_in_env
      script: |
        echo "Switching context"
        scripts/dev/switch_context.sh "${build_variant}"
        echo "Finished switching context"

  python_venv: &python_venv
    command: subprocess.exec
    type: setup
    params:
      command: /opt/python/3.9/bin/python3 -m venv --upgrade-deps ./venv

  python_requirements: &python_requirements
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      command: scripts/evergreen/run_python.sh -m pip install -r requirements.txt --quiet --no-warn-script-location

  "clone":
    - command: subprocess.exec
      type: setup
      params:
        command: "mkdir -p src/github.com/10gen"
    - command: git.get_project
      type: setup
      params:
        directory: src/github.com/10gen/ops-manager-kubernetes
    - *setup_context

  setup_kubectl: &setup_kubectl
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      binary: scripts/evergreen/setup_kubectl.sh

  setup_jq: &setup_jq
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      binary: scripts/evergreen/setup_jq.sh

  setup_shellcheck:
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_to_path:
        - ${workdir}/bin
      binary: scripts/evergreen/setup_shellcheck.sh

  setup_aws: &setup_aws
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_to_path:
        - ${workdir}/bin
      binary: scripts/evergreen/setup_aws.sh

  # configures Docker size, installs the Kind binary (if necessary)
  setup_kind: &setup_kind
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_to_path:
        - ${workdir}/bin
      binary: scripts/evergreen/setup_kind.sh

  setup_docker_datadir: &setup_docker_datadir
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      binary: scripts/evergreen/configure-docker-datadir.sh

  setup_preflight:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        binary: scripts/evergreen/setup_preflight.sh
    # The python binary is in a different location for RHEL machines so we can't use the same process
    # for creating the virtual environment.
    - command: subprocess.exec
      type: setup
      params:
        command: python3 -m venv --upgrade-deps ./venv
    - *python_requirements

  setup_prepare_openshift_bundles:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: scripts/evergreen/setup_yq.sh
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: scripts/evergreen/setup_prepare_openshift_bundles.sh

  install_olm:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: scripts/evergreen/operator-sdk/install-olm.sh

  prepare_openshift_bundles_for_e2e:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: scripts/evergreen/operator-sdk/prepare-openshift-bundles-for-e2e.sh

  setup_docker_sbom:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/setup_docker_sbom.sh

  # Logs into all used registries
  configure_docker_auth: &configure_docker_auth
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_to_path:
        - ${workdir}/bin
      binary: scripts/dev/configure_docker_auth.sh

  lint_repo:
    - *python_venv
    - *python_requirements
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: scripts/evergreen/setup_yq.sh
    - command: github.generate_token
      params:
        owner: 10gen
        repo: ops-manager-kubernetes
        expansion_name: GITHUB_TOKEN_READ
    - command: subprocess.exec
      type: test
      params:
        add_to_path:
          - ${workdir}/bin
          - ${workdir}/venv/bin
        include_expansions_in_env:
          - GITHUB_TOKEN_READ
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/check_precommit.sh

  # Configures docker authentication to ECR and RH registries.
  setup_building_host:
    - *switch_context
    - *setup_aws
    - *configure_docker_auth
    - *setup_docker_datadir

  prune_docker_resources:
    - command: subprocess.exec
      type: setup
      params:
        command: "docker system prune -a -f"

  # the task configures the set of tools necessary for any task working with K8 cluster:
  # installs kubectl, jq, kind (if necessary), configures docker authentication
  download_kube_tools:
    - *switch_context
    - *setup_kubectl
    - *setup_jq
    # we need aws to configure docker authentication
    - *setup_aws
    - *configure_docker_auth
    - *setup_kind

  teardown_kubernetes_environment:
    - command: shell.exec
      type: setup
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          scripts/evergreen/teardown_kubernetes_environment.sh

  # Makes sure a kubectl context is defined.
  setup_kubernetes_environment_p: &setup_kubernetes_environment_p
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_to_path:
        - ${workdir}/bin
      binary: scripts/evergreen/setup_kubernetes_environment.sh

  setup_kubernetes_environment:
    - *setup_kubernetes_environment_p
    # After setting up KUBE, we need to update the KUBECONFIG and other env vars.
    - *switch_context

  # cleanup_exec_environment is a very generic name when the only thing this function
  # does is to clean the logs directory. In the future, more "commands" can be
  # added to it with more clearing features, when needed.
  cleanup_exec_environment:
    - command: shell.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          rm -rf logs

  quay_login:
    - command: subprocess.exec
      type: setup
      params:
        command: "docker login quay.io -u ${quay_prod_username} -p ${quay_prod_robot_token}"

  setup_cloud_qa:
    - *switch_context
    - command: shell.exec
      type: setup
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          source .generated/context.export.env
          scripts/evergreen/e2e/setup_cloud_qa.py create
    # The additional switch is needed, since we now have created the needed OM exports.
    - *switch_context

  teardown_cloud_qa:
    - command: shell.exec
      type: setup
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          source .generated/context.export.env
          scripts/evergreen/e2e/setup_cloud_qa.py delete

  ### Publish and release image ###

  # Tags and pushes an image into an external Docker registry. The source image
  # needs to exist before it can be pushed to a remote registry.
  # It is expected that IMAGE_SOURCE is accessible with no authentication (like a
  # local image), and the IMAGE_TARGET will be authenticated with DOCKER_* series of
  # environment variables.
  release_docker_image_to_registry:
    - command: subprocess.exec
      type: system
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        include_expansions_in_env:
          - tag_source
          - tag_dest
          - image_source
          - image_target
          - docker_username
          - docker_password
        binary: scripts/evergreen/tag_push_docker_image.sh

  #
  # Performs some AWS cleanup
  #
  prepare_aws: &prepare_aws
    command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_to_path:
        - ${workdir}/bin
      command: scripts/evergreen/prepare_aws.sh

  build-dockerfiles:
    - *python_venv
    - *python_requirements
    - command: subprocess.exec
      type: setup
      params:
        add_to_path:
          - ${workdir}/bin
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/run_python.sh scripts/update_supported_dockerfiles.py
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        include_expansions_in_env:
          - triggered_by_git_tag
        # if you ever change the target folder structure, the same needs to be reflected in PCT
        command: "tar -czvf ./public/dockerfiles-${triggered_by_git_tag}.tgz ./public/dockerfiles"

  enable_QEMU:
    - command: shell.exec
      type: setup
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          echo "Enabling QEMU building for Docker"
          sudo docker run --rm --privileged 268558157000.dkr.ecr.eu-west-1.amazonaws.com/docker-hub-mirrors/multiarch/qemu-user-static --reset -p yes

  upload_dockerfiles:
    - command: s3.put
      params:
        aws_key: ${enterprise_aws_access_key_id}
        aws_secret: ${enterprise_aws_secret_access_key}
        local_file: src/github.com/10gen/ops-manager-kubernetes/public/dockerfiles-${triggered_by_git_tag}.tgz
        remote_file: bundles/dockerfiles-${triggered_by_git_tag}.tgz
        bucket: operator-e2e-bundles
        permissions: public-read
        content_type: application/x-binary

  # upload_e2e_logs has the responsibility of dumping as much information as
  # possible into the S3 bucket that corresponds to this ${version}. The
  # Kubernetes cluster where the test finished running, should still be
  # reachable. Note that after a timeout, Evergreen kills the running process
  # and any running container in the host (which kills Kind).
  upload_e2e_logs:
    - command: s3.put
      params:
        aws_key: ${enterprise_aws_access_key_id}
        aws_secret: ${enterprise_aws_secret_access_key}
        local_files_include_filter:
          - src/github.com/10gen/ops-manager-kubernetes/logs/*
        remote_file: logs/${task_id}/${execution}/
        bucket: operator-e2e-artifacts
        permissions: public-read
        content_type: text/plain
    - command: attach.xunit_results
      params:
        file: "src/github.com/10gen/ops-manager-kubernetes/logs/myreport.xml"

  preflight_image:
    - *switch_context
    - command: subprocess.exec
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        include_expansions_in_env:
          - image_version
          - rh_pyxis
        binary: scripts/evergreen/run_python.sh scripts/preflight_images.py --image ${image_name} --submit "${preflight_submit}"

  build_multi_cluster_binary:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/build_multi_cluster_kubeconfig_creator.sh

  build_and_push_appdb_database:
    - command: subprocess.exec
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes/docker/mongodb-enterprise-appdb-database
        binary: ./build_and_push_appdb_database_images.sh
        add_to_path:
          - ${workdir}/bin
          - ${workdir}

  pipeline:
    - *python_venv
    - *python_requirements
    - *switch_context
    - command: shell.exec
      type: setup
      params:
        shell: bash
        script: |
          # Docker Hub workaround
          # docker buildx needs the moby/buildkit image when setting up a builder so we pull it from our mirror
          docker buildx create --driver=docker-container --driver-opt=image=268558157000.dkr.ecr.eu-west-1.amazonaws.com/docker-hub-mirrors/moby/buildkit:buildx-stable-1 --use
          docker buildx inspect --bootstrap
    - command: subprocess.exec
      retry_on_failure: true
      type: setup
      params:
        shell: bash
        include_expansions_in_env:
          - version_id
          - registry
          - image_name
          - skip_tags
          - include_tags
          - distro
          - is_patch
          - GRS_USERNAME
          - GRS_PASSWORD
          - PKCS11_URI
          - ARTIFACTORY_USERNAME
          - ARTIFACTORY_PASSWORD
          - triggered_by_git_tag
          - pin_tag_at
          - SILK_CLIENT_ID
          - SILK_CLIENT_SECRET
          - otel_trace_id
          - otel_parent_id
          - otel_collector_endpoint
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/run_python.sh pipeline.py --include ${image_name} --parallel --sign

  teardown_cloud_qa_all:
    - *python_venv
    - *python_requirements
    - *switch_context
    - command: shell.exec
      type: setup
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          source .generated/context.export.env
          scripts/evergreen/e2e/setup_cloud_qa.py delete_all

  # Updates current expansions with variables from release.json file.
  # Use e.g. ${mongoDbOperator} afterwards.
  update_evergreen_expansions:
    - command: subprocess.exec
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: "scripts/evergreen/generate_evergreen_expansions.sh"
    - command: expansions.update
      params:
        file: "src/github.com/10gen/ops-manager-kubernetes/evergreen_expansions.yaml"

  # Uploads openshift bundle specified by bundle_file_name argument.
  upload_openshift_bundle:
    - command: s3.put
      params:
        aws_key: ${enterprise_aws_access_key_id}
        aws_secret: ${enterprise_aws_secret_access_key}
        local_file: src/github.com/10gen/ops-manager-kubernetes/bundle/${bundle_file_name}
        remote_file: bundles/${bundle_file_name}
        bucket: operator-e2e-bundles
        permissions: public-read
        content_type: application/x-binary

  prepare_openshift_bundles:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        command: scripts/evergreen/operator-sdk/prepare-openshift-bundles.sh

  # Performs some AWS cleanup
  cleanup_aws:
    - *setup_jq
    - *setup_aws
    - *prepare_aws
    - command: subprocess.exec
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        # Below script deletes agent images created for an Evergreen patch older than 1 day
        command: scripts/evergreen/run_python.sh scripts/evergreen/periodic-cleanup-aws.py

  ### Test Functions ###

  #
  # e2e_test is the main function used to run the e2e tests. It expects Ops
  # Manager to be running (local to the Kubernetes cluster or Cloud Manager) and
  # its configuration to exist in a ${workdir}/.ops-manager-env file.
  #
  # The e2e script will run all the tasks that are needed by the e2e tests like
  # fetching the OM API credentials to use and create the Secret and ConfigMap
  # objects that are required.
  #
  # At this point, the Kubernetes environment should be configured already
  # (kubectl configuration points to the Kubernetes cluster where we run the tests).
  #
  # Please note: There are many ENV variables passed to the `e2e` script, so try
  # to not add more. If this is required, discuss your use case with the team first.
  #
  e2e_test:
    - command: subprocess.exec
      type: test
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        include_expansions_in_env:
          - otel_parent_id
          - branch_name
          - github_commit
          - revision
          - github_pr_number
          - project_identifier
          - revision_order_id
        add_to_path:
          - ${workdir}/bin
        binary: scripts/evergreen/e2e/e2e.sh

  e2e_test_perf:
    - command: subprocess.exec
      type: test
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        include_expansions_in_env:
          - otel_parent_id
          - branch_name
          - github_commit
          - revision
          - github_pr_number
          - project_identifier
          - revision_order_id
        add_to_path:
          - ${workdir}/bin
        env:
          PERF_TASK_DEPLOYMENTS: ${PERF_TASK_DEPLOYMENTS}
          PERF_TASK_REPLICAS: ${PERF_TASK_REPLICAS}
          TEST_NAME_OVERRIDE: ${TEST_NAME_OVERRIDE}
        binary: scripts/evergreen/e2e/e2e.sh

  test_operator:
    - *python_venv
    - *python_requirements
    - command: shell.exec
      type: test
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          source .generated/context.export.env
          make test-race

  test_sboms:
    - *python_venv
    - *python_requirements
    - command: shell.exec
      type: test
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          source .generated/context.export.env
          make sbom-tests

  generate_perf_tests_tasks:
    - *switch_context
    - *python_venv
    - *python_requirements
    - command: shell.exec
      type: setup
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          source .generated/context.export.env
          scripts/evergreen/run_python.sh scripts/evergreen/e2e/performance/create_variants.py ${variant} ${size}> evergreen_tasks.json
          echo "tasks to run:"
          cat evergreen_tasks.json
    - command: generate.tasks
      params:
        files:
          - evergreen_tasks.json

  ### Other ###

  run_retry_script:
    - command: shell.exec
      type: test
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        include_expansions_in_env:
          - EVERGREEN_API_KEY
          - EVERGREEN_USER
          - evergreen_retry
        env:
          EVERGREEN_RETRY: ${evergreen_retry}
        script: |
          scripts/evergreen/retry-evergreen.sh ${version_id}

  # This is a generic function for conditionally running given task.
  # It works by appending <task> to <variant> if <condition_script> returns no error.
  #
  # It has 3 input parameters:
  #  - condition_script: path to the script that will be executed.
  #     Error code == 0 resulting from the scripts indicates that <task> should be added dynamically to <variant>
  #     Error code != 0 means that the task will not be executed
  #  - variant: variant to which task will be appended
  #  - task: task name to be executed
  #
  # Example usage:
  #  - func: run_task_conditionally
  #    vars:
  #      condition_script: scripts/evergreen/should_prepare_openshift_bundles.sh
  #      variant: prepare_openshift_bundles
  #      task: prepare_and_upload_openshift_bundles
  run_task_conditionally:
    - command: shell.exec
      params:
        shell: bash
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          if ${condition_script}; then
            echo "Adding ${task} task to ${variant} variant"
            scripts/evergreen/add_evergreen_task.sh ${variant} ${task}
          else
            echo "skipping task ${task} due to ${condition_script} result: $?"
          fi
    - command: generate.tasks
      params:
        files:
          - evergreen_tasks.json
        optional: true
