ignore:
  - "*.md"
  - "public/support/*"
  - "public/samples/*"
stepback: true

# Ops Manager image building & pushing takes a long time
exec_timeout_secs: 3600
variables:
  - &ops_manager_40_first
    ops_manager_version: "4.0.11.50485.20190502T1847Z-1_test"
    ops_manager_namespace: "operator-testing-40-first"
    node_port: 30041
  - &ops_manager_42_current
    ops_manager_version: "4.2.4.56729.20191105T2247Z-1"
    ops_manager_namespace: "operator-testing-42-current"
    node_port: 30043

  - &cloud_manager_qa
    ops_manager_version: "cloud_qa"

    # Openshift v3 Testing Environment
  - &kubernetes_environment_openshift_3
    kube_environment_name: openshift_3
    managed_security_context: "true"

    # Kops Vanilla Kubernetes
  - &kubernetes_environment_vanilla
    kube_environment_name: vanilla

  - &kubernetes_environment_kind
    kube_environment_name: kind

  - &go_bin
    "/opt/golang/go1.13/bin"

  - &go_options
    GO111MODULE: "on"
    GOFLAGS: "-mod=vendor"
    GOROOT: "/opt/golang/go1.13"

functions:
  "golint":
    - command: subprocess.exec
      type: test
      params:
        add_to_path:
          - *go_bin
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        env:
          WORKDIR: ${workdir}
          <<: *go_options
        binary: scripts/evergreen/lint_code.sh

  "clone":
    - command: subprocess.exec
      type: setup
      params:
        command: "mkdir -p src/github.com/10gen"
    - command: git.get_project
      type: setup
      params:
        directory: src/github.com/10gen/ops-manager-kubernetes

  "test_operator":
    - command: subprocess.exec
      type: test
      params:
        add_to_path:
          - *go_bin
          - ${workdir}/bin
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        env:
          WORKDIR: ${workdir}
          <<: *go_options

          CONTINUE: "true"
        binary: scripts/evergreen/build_operator

  "build_operator":
    - command: subprocess.exec
      type: setup
      params:
        add_to_path:
        - *go_bin
        - ${workdir}/bin
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        env:
          WORKDIR: ${workdir}
          SKIP_TESTING: "true"

          IMAGE_TYPE: ${distro}
          <<: *go_options

        binary: scripts/evergreen/build_operator

  "build_database":
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - *go_bin
        env:
          <<: *go_options
        command: "make -C docker/mongodb-enterprise-database prepare-build IMAGE_TYPE=${distro}"

    - command: s3.put
      params:
        aws_key: ${mms_build_s3_aws_access_key}
        aws_secret: ${mms_build_s3_aws_secret}
        local_file: src/github.com/10gen/ops-manager-kubernetes/docker/mongodb-enterprise-operator/content/mongodb-enterprise-operator
        remote_file: ops-manager-operator/${revision}/mongodb-enterprise-operator
        bucket: ops-manager-kubernetes-build
        permissions: public-read
        content_type: application/octet-stream

  # push_versioned_binaries will build the operator and readinessprobe binaries,
  # put them into a tar.gz file and upload them to S3, indicating the release version.
  # this is for customers or any other third party consumers to be able to build
  # their own Docker images.
  "push_versioned_binaries":
    - command: shell.exec
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          export PATH=${workdir}/bin:$PATH
          set -o xtrace

          release="$(jq --raw-output .mongodbOperator < release.json)"
          mkdir -p releases/

          mv docker/mongodb-enterprise-operator/content/mongodb-enterprise-operator .
          mv docker/mongodb-enterprise-database/content/readinessprobe .

          tar -czf releases/mongodb-enterprise-operator-binaries-release-$release.tar.gz \
             mongodb-enterprise-operator \
             readinessprobe

    - command: s3.put
      params:
        aws_key: ${mms_build_s3_aws_access_key}
        aws_secret: ${mms_build_s3_aws_secret}
        local_files_include_filter:
          - src/github.com/10gen/ops-manager-kubernetes/releases/*
        remote_file: releases/
        bucket: ops-manager-kubernetes-build
        permissions: public-read
        content_type: application/octet-stream

  # upload_e2e_logs has the responsibility of dumping as much information as
  # posible into the S3 bucket that corresponds to this ${version}. The
  # Kubernetes cluster where the test finished running, should still be
  # reachable. Note that after a timeout, Evergreen kills the running process
  # and any running container in the host (which kills Kind).
  upload_e2e_logs:
    # TODO: note that the bucket is public so far - there was something with
    # permissions that didn't allow uploads for the eng test acccount.
    - command: s3.put
      params:
        aws_key: ${mms_eng_test_aws_access_key}
        aws_secret: ${mms_eng_test_aws_secret}
        local_files_include_filter:
          - src/github.com/10gen/ops-manager-kubernetes/logs/*
        remote_file: logs/${task_id}/
        bucket: operator-e2e-artifacts
        permissions: public-read
        content_type: text/plain
    - command: subprocess.exec
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        # Logs need to be removed after each task run or they will be pushed
        # again after next task.
        command: rm -rf logs/*

  # push the latest build of the operator to s3 for the RH build-service to be able to build the RHEL image.
  push_operator_binary_for_rhel:
    - command: s3.put
      params:
        aws_key: ${mms_build_s3_aws_access_key}
        aws_secret: ${mms_build_s3_aws_secret}
        local_file: src/github.com/10gen/ops-manager-kubernetes/docker/mongodb-enterprise-operator/content/mongodb-enterprise-operator
        remote_file: ops-manager-operator/latest/mongodb-enterprise-operator
        bucket: ops-manager-kubernetes-build
        permissions: public-read
        content_type: application/octet-stream

  push_database_readiness_probe_for_rhel:
    - command: s3.put
      params:
        aws_key: ${mms_build_s3_aws_access_key}
        aws_secret: ${mms_build_s3_aws_secret}
        local_file: src/github.com/10gen/ops-manager-kubernetes/docker/mongodb-enterprise-database/content/readinessprobe
        remote_file: ops-manager-operator/latest/database-readiness-probe
        bucket: ops-manager-kubernetes-build
        permissions: public-read
        content_type: application/octet-stream

  "build_rhel_images":
    - command: shell.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          export PATH=${workdir}/bin:$PATH

          if [ "${is_patch}" != "true" ]; then
            echo "Releasing is done only from patches"
            exit 0
          fi

          set -euo

          release="$(jq --raw-output .mongodbOperator < release.json)"

          echo "Performing release $release!"
          scripts/evergreen/build_operator_rhel.sh $release ${rhc_operator_pid}
          scripts/evergreen/build_operator_rhel.sh $release ${rhc_database_pid}

  # Install and configures ecr-login-helper, allowing for accessing the ECR registry
  # without calling docker login and in the ECR case, avoiding also calling
  # `aws ecr get login`. This is a binary that should run on every distro.
  # BIN_PATH is used to define where to save the binary. This is added to the $PATH
  # in subsequent functions that need this program.
  setup_ecr_login_helper:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/setup_ecr_login_helper

  "setup_jq":
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_expansions_to_env: true
        binary: scripts/evergreen/setup_jq.sh

  "setup_aws":
    - command: subprocess.exec
      type: setup
      params:
        binary: src/github.com/10gen/ops-manager-kubernetes/scripts/evergreen/setup_aws

  "setup_docker":
    - command: subprocess.exec
      type: setup
      params:
        binary: src/github.com/10gen/ops-manager-kubernetes/scripts/evergreen/setup_docker

  download_kube_tools:
    - command: subprocess.exec
      type: setup
      params:
        add_expansions_to_env: true
        binary: src/github.com/10gen/ops-manager-kubernetes/scripts/evergreen/setup_kubectl

    - command: subprocess.exec
      type: setup
      params:
        add_expansions_to_env: true
        binary: src/github.com/10gen/ops-manager-kubernetes/scripts/evergreen/setup_jq.sh

    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_expansions_to_env: true
        binary: scripts/evergreen/setup_ecr_login_helper

    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_expansions_to_env: true
        add_to_path:
          - ${workdir}/bin
        env:
          AWS_ACCESS_KEY_ID: ${mms_eng_test_aws_access_key}
          AWS_SECRET_ACCESS_KEY: ${mms_eng_test_aws_secret}
          AWS_DEFAULT_REGION: ${mms_eng_test_aws_region}
        binary: scripts/evergreen/setup_kind

  teardown_kubernetes_environment:
  - command: subprocess.exec
    type: setup
    params:
      command: "${workdir}/bin/kind delete cluster"

  setup_kubernetes_environment:
  - command: shell.exec
    type: setup
    params:
      shell: bash
      script: |
          export WORKDIR=${workdir}
          export BINDIR=$WORKDIR/bin
          export PATH=$BINDIR:$PATH

          if [ "${kube_environment_name}" = "openshift_3" ]; then
            echo "Downloading OC & setting up Openshift cluster"
            OC_PKG=oc-linux.tar.gz
            curl -s -L https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz --output $OC_PKG
            tar xfz $OC_PKG &> /dev/null
            mv openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit/oc $BINDIR

            echo "Setting up OpenShift variant"
            echo "Token: ${openshift_cluster_token}"
            oc login ${openshift_cluster_url} --token=${openshift_cluster_token} --insecure-skip-tls-verify
            kubectl config use-context default/master-openshift-cluster-mongokubernetes-com:8443/admin
          elif [ "${kube_environment_name}" = "vanilla" ]; then
            if [ ! -z ${cluster_name} ]; then
              export CLUSTER=${cluster_name}
            else
              export CLUSTER=e2e.mongokubernetes.com
            fi

            # AWS creds
            export AWS_ACCESS_KEY_ID=${mms_eng_test_aws_access_key}
            export AWS_SECRET_ACCESS_KEY=${mms_eng_test_aws_secret}
            export AWS_REGION=${mms_eng_test_aws_region}
            export AWS_DEFAULT_REGION=${mms_eng_test_aws_region}
            export KOPS_STATE_STORE=s3://kube-om-state-store

            echo "Downloading kops"
            curl -s -L https://github.com/kubernetes/kops/releases/download/1.14.0/kops-linux-amd64 -o kops
            chmod +x kops
            mv kops $BINDIR

            if ! kops get clusters | grep -q $CLUSTER; then
              echo "Cluster $CLUSTER not found, exiting..."
              echo run "make recreate-e2e-kops imsure=yes cluster=$CLUSTER"
              kops get clusters
              exit 1
            fi

            kops export kubecfg $CLUSTER

          elif [ "${kube_environment_name}" = "kind" ]; then
            echo "Starting Kind"
            kind create cluster --config $HOME/.operator-dev/kind-ecr-config.yaml

            echo "Setting context to Kind"
            kubectl config use-context kind-kind
          else
            echo "kube_environment_name not recognized"
            echo "value is <<${kube_environment_name}>>. If empty it means it was not set"
          fi


  "gotest_parse_files":
    - command: gotest.parse_files
      type: test
      params:
        files: ["*.suite", "src/**/*.suite"]

  # Uploads the Docker build context to S3 in order for Kaniko to be able to build the images.
  upload_e2e_build_context:
  - command: subprocess.exec
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_expansions_to_env: true
      binary: scripts/evergreen/upload_e2e_build_context.sh
  - command: s3.put
    params:
      aws_key: ${mms_build_s3_aws_access_key}
      aws_secret: ${mms_build_s3_aws_secret}
      local_files_include_filter:
        - src/github.com/10gen/ops-manager-kubernetes/*-context.tar.gz
      remote_file: ops-manager-operator/${version_id}:${distro}/contexts/
      bucket: ops-manager-kubernetes-build
      permissions: public-read
      content_type: application/octet-stream

  kaniko_build:
  - command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_expansions_to_env: true
      add_to_path:
      - ${workdir}/bin
      binary: scripts/evergreen/build_docker_image.sh

  kaniko_wait:
  - command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      add_expansions_to_env: true
      add_to_path:
      - ${workdir}/bin
      binary: scripts/evergreen/wait_docker_image.sh
    
  "build_and_push_om_test_images":
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - *go_bin
          - ${workdir}/bin
        add_expansions_to_env: true
        env:
          <<: *go_options

          AWS_ACCESS_KEY_ID: ${mms_eng_test_aws_access_key}
          AWS_SECRET_ACCESS_KEY: ${mms_eng_test_aws_secret}
          AWS_DEFAULT_REGION: ${mms_eng_test_aws_region}

          IN_MEMORY_CONTEXT: "true"
          REPO_URL: "268558157000.dkr.ecr.us-east-1.amazonaws.com/dev"
          GITHUB_TOKEN: ${GITHUB_TOKEN}

          CLUSTER_TYPE: ${cluster_type}

        command: "make om-batch scope=4.2.0,4.2.3,4.2.4"

  "build_and_push_om_test_images_the_rest":
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - *go_bin
          - ${workdir}/bin
        add_expansions_to_env: true
        env:
          <<: *go_options

          AWS_ACCESS_KEY_ID: ${mms_eng_test_aws_access_key}
          AWS_SECRET_ACCESS_KEY: ${mms_eng_test_aws_secret}
          AWS_DEFAULT_REGION: ${mms_eng_test_aws_region}

          IN_MEMORY_CONTEXT: "true"
          REPO_URL: "268558157000.dkr.ecr.us-east-1.amazonaws.com/dev"
          GITHUB_TOKEN: ${GITHUB_TOKEN}

          CLUSTER_TYPE: ${cluster_type}

        command: "make om-batch scope=4.2.6,4.2.7"

  "build_and_push_image":
    - command: shell.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        script: |
          set +x
          # Releases are performed only for patches
          if [ -n "${release_object}" ] && [ "${is_patch}" != "true" ]; then
            echo "Releasing is done only from patches"
            exit 0
          fi

          # AWS creds
          export AWS_ACCESS_KEY_ID=${mms_eng_test_aws_access_key}
          export AWS_SECRET_ACCESS_KEY=${mms_eng_test_aws_secret}

          # Quay prod creds
          export QUAY_PROD_USER=${quay_prod_username}
          export QUAY_PROD_PASSWORD=${quay_prod_robot_token}

          if [ "${tag_images_with_version}" = "true" ]; then
            export REVISION=${version_id}
          fi

          python3 -m venv venv
          source venv/bin/activate
          python3 -m pip install -r scripts/evergreen/requirements.txt

          # Always consider the caveat of "${var} vs $var" in evergreen!!
          docker_args="${docker_args}"

          # Releases override REVISION from predefined tags
          if [ -n "${release_object}" ]; then
            export REVISION=$(./scripts/evergreen/read_release_version.py --release-app ${release_object})
          fi

          ./scripts/evergreen/build_and_push.py \
              --image ${image_name} \
              --tag "$REVISION" \
              --registry "${env}" \
              --path "${path}" \
              --docker-args "$docker_args" \
              $(if [ -n "${release_object}" ]; then echo '--with-latest-tag'; fi)

  setup_cloud_qa:
  - command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      env:
        NAMESPACE_FILE: ${workdir}/.namespace
        ENV_FILE: ${workdir}/.ops-manager-env
      include_expansions_in_env:
      - e2e_cloud_qa_baseurl
      - e2e_cloud_qa_orgid_owner
      - e2e_cloud_qa_apikey_owner
      - e2e_cloud_qa_user_owner
      - ops_manager_version
      - task_name

      command: "scripts/evergreen/e2e/setup_cloud_qa.py create"

  teardown_cloud_qa:
  - command: subprocess.exec
    type: setup
    params:
      working_dir: src/github.com/10gen/ops-manager-kubernetes
      include_expansions_in_env:
      - e2e_cloud_qa_baseurl
      - e2e_cloud_qa_orgid_owner
      - e2e_cloud_qa_apikey_owner
      - e2e_cloud_qa_user_owner
      - ops_manager_version
      env:
        NAMESPACE_FILE: ${workdir}/.namespace
        ENV_FILE: ${workdir}/.ops-manager-env

      command: "scripts/evergreen/e2e/setup_cloud_qa.py delete"

  # Exit if repository is not clean.
  guard_git_repo_is_clean:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/guard_git_repo_is_clean

  # This is a blocker for the release process. It will *always* fail and needs to be overriden
  # if the release needs to proceed.
  release_blocker:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        binary: scripts/evergreen/release_blocker

  # Tags and pushes an image into an external Docker registry. The source image
  # needs to exist before it can be pushed to a remote registry.
  # It is expected that IMAGE_SOURCE is accessible with no authentication (like a
  # local image), and the IMAGE_TARGET will be authenticated with DOCKER_* series of
  # environemnt variables.
  release_docker_image_to_registry:
    - command: subprocess.exec
      type: system
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        env:
          DOCKER_REGISTRY: ${docker_registry}
          DOCKER_LOGIN_USER: ${docker_username}
          DOCKER_LOGIN_PASSWORD: ${docker_password}
          AWS_ACCESS_KEY_ID: ${mms_eng_test_aws_access_key}
          AWS_SECRET_ACCESS_KEY: ${mms_eng_test_aws_secret}

          VERSIONS: ${versions}
          TAG_SOURCE: ${tag_source}
          TAG_DEST: ${tag_dest}
          IMAGE_SOURCE: ${image_source}
          IMAGE_TARGET: ${image_target}

        binary: scripts/evergreen/tag_push_docker_image.sh

  #
  # e2e_test is the main function used to run the e2e tests. It expects Ops
  # Manager to be running (local to the Kubernetes cluster or Cloud Manager) and
  # its configuration to exist in a ${workdir}/.ops-manager-env file.
  #
  # The e2e script will run all the tasks that are needed by the e2e tests like
  # fetching the OM API credentials to use and create the Secret and ConfigMap
  # objects that are required.
  #
  # At this point, the Kubernetes environment should be configured already
  # (kubectl configuration points to the Kubernetes cluster where we run the tests).
  #
  # Please note: There are many ENV variables passed to the `e2e` script, so try
  # to not add more. If this is required, discuss your use case with the team first.
  #
  e2e_test:
    - command: subprocess.exec
      type: test
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        env:
          OPERATOR_VERSION: ${version_id}
          REGISTRY: ${ecr_registry}/dev/${distro}
          MANAGED_SECURITY_CONTEXT: ${managed_security_context}
          TASK_ID: ${task_id}
          TASK_NAME: ${task_name}
          OPS_MANAGER_NAMESPACE: ${ops_manager_namespace}
          OPS_MANAGER_ENV: ${workdir}/.ops-manager-env
          NAMESPACE_FILE: ${workdir}/.namespace
          NODE_PORT: ${node_port}
          AWS_ACCESS_KEY_ID: ${mms_eng_test_aws_access_key}
          AWS_SECRET_ACCESS_KEY: ${mms_eng_test_aws_secret}
          OPERATOR_VERSION_UPGRADE_FROM: ${from_version}
          MMS_VERSION: ${ops_manager_version}
          WATCH_NAMESPACE: ${watch_namespace}
          STATIC_NAMESPACE: ${static_namespace}
          TEST_MODE: ${test_mode}

        binary: scripts/evergreen/e2e/e2e

  #
  # This function makes sure the target Kubernetes cluster has the required Ops
  # Manager services running. It also fix a few problems that could exist and
  # deploys the "cluster_cleaner".
  #
  prepare_test_env:
    - command: subprocess.exec
      type: setup
      params:
        working_dir: src/github.com/10gen/ops-manager-kubernetes
        add_to_path:
          - ${workdir}/bin
        env:
          AWS_ACCESS_KEY_ID: ${mms_eng_test_aws_access_key}
          AWS_SECRET_ACCESS_KEY: ${mms_eng_test_aws_secret}
          AWS_DEFAULT_REGION: ${mms_eng_test_aws_region}

        command: "scripts/evergreen/prepare_test_env ${ops_manager_namespace} ${ops_manager_version} ${node_port}"

tasks:
- name: unit_tests
  tags: ["unit_tests"]
  commands:
    - func: "setup_jq"
    - func: "test_operator"
    - func: "gotest_parse_files"

- name: unit_tests_lint
  tags: ["unit_tests"]
  commands:
    - func: "golint"

- name: release_blocker
  commands:
  - func: clone
  - func: release_blocker

# release_ops_manager_rhel Releases the just build Docker image
# with a release image tag.
# The registry location (variable with name `image_target`) is obtained from RedHat Connect.
- name: release_ops_manager_rh_connect
  commands:
    - func: clone
    - func: guard_git_repo_is_clean
    - func: setup_jq
    - func: setup_ecr_login_helper

    - func: release_docker_image_to_registry
      vars:
        versions: '$(jq --raw-output ".opsManagerImages[] | .version" < release.json)'
        tag_source: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        tag_dest: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/rhel/mongodb-enterprise-ops-manager
        image_target: scan.connect.redhat.com/ospid-b419ca35-17b4-4655-adee-a34e704a6835/mongodb-enterprise-ops-manager
        docker_password: ${rhc_om_pid}

    - func: release_docker_image_to_registry
      vars:
        versions: '$(jq --raw-output ".opsManagerImages[] | .version" < release.json)'
        tag_source: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        tag_dest: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/rhel/mongodb-enterprise-appdb
        image_target: scan.connect.redhat.com/ospid-31c2f102-af15-4e15-87b9-30710586d9ad/mongodb-enterprise-appdb
        docker_password: ${rhc_appdb_pid}

# release_operator_rh_connect Releases the Operator and Database image to RH Connect.
- name: release_operator_rh_connect
  commands:
    - func: clone
    - func: guard_git_repo_is_clean
    - func: setup_jq
    - func: setup_ecr_login_helper

    - func: release_docker_image_to_registry
      vars:
        versions: ${version_id}
        tag_source: '$(echo $version)'
        tag_dest: '$(git describe --dirty)'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/rhel/mongodb-enterprise-operator
        image_target: scan.connect.redhat.com/ospid-5558a531-617e-46d7-9320-e84d3458768a/mongodb-enterprise-operator
        docker_password: ${rhc_operator_pid}

    - func: release_docker_image_to_registry
      vars:
        versions: ${version_id}
        tag_source: '$(echo $version)'
        tag_dest: '$(git describe --dirty)'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/rhel/mongodb-enterprise-database
        image_target: scan.connect.redhat.com/ospid-239de277-d8bb-44b4-8593-73753752317f/mongodb-enterprise-database
        docker_password: ${rhc_database_pid}

- name: release_ops_manager_quay
  commands:
    - func: clone
    - func: guard_git_repo_is_clean
    - func: setup_jq
    - func: setup_ecr_login_helper

    - func: release_docker_image_to_registry
      vars:
        versions: '$(jq --raw-output ".opsManagerImages[] | .version" < release.json)'
        tag_source: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        tag_dest: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-ops-manager
        image_target: quay.io/mongodb/mongodb-enterprise-ops-manager
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

    - func: release_docker_image_to_registry
      vars:
        versions: '$(jq --raw-output ".opsManagerImages[] | .version" < release.json)'
        tag_source: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        tag_dest: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-appdb
        image_target: quay.io/mongodb/mongodb-enterprise-appdb
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

- name: release_operator_quay
  commands:
    - func: clone
    - func: guard_git_repo_is_clean
    - func: setup_jq
    - func: setup_ecr_login_helper

    - func: release_docker_image_to_registry
      vars:
        versions: ${version_id}
        tag_source: '$(echo $version)'
        tag_dest: '$(git describe --dirty)'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-operator
        image_target: quay.io/mongodb/mongodb-enterprise-operator
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

    - func: release_docker_image_to_registry
      vars:
        versions: ${version_id}
        tag_source: '$(echo $version)'
        tag_dest: '$(git describe --dirty)'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-database
        image_target: quay.io/mongodb/mongodb-enterprise-database
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

- name: prerelease_master_images
  commands:
    - func: clone
    - func: setup_jq
    - func: setup_ecr_login_helper

    - func: release_docker_image_to_registry
      vars:
        versions: ${version_id}
        tag_source: '$(echo $version)'
        tag_dest: '$(git describe --dirty)'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-operator
        image_target: quay.io/mongodb/mongodb-enterprise-operator-prerelease
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

    - func: release_docker_image_to_registry
      vars:
        versions: ${version_id}
        tag_source: '$(echo $version)'
        tag_dest: '$(git describe --dirty)'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-database
        image_target: quay.io/mongodb/mongodb-enterprise-database-prerelease
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

    - func: release_docker_image_to_registry
      vars:
        versions: '$(jq --raw-output ".opsManagerImages[] | .version" < release.json)'
        tag_source: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        tag_dest: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-ops-manager
        image_target: quay.io/mongodb/mongodb-enterprise-ops-manager-prerelease
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

    - func: release_docker_image_to_registry
      vars:
        versions: '$(jq --raw-output ".opsManagerImages[] | .version" < release.json)'
        tag_source: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        tag_dest: '$(join "-" $version $(echo "operator$(git describe --dirty)"))'
        image_source: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-appdb
        image_target: quay.io/mongodb/mongodb-enterprise-appdb-prerelease
        docker_username: ${quay_prod_username}
        docker_password: ${quay_prod_robot_token}

# build_binaries builds and pushes binaries required to build the Database and
# Operator Docker images. Currently these are the actual operator and the
# readinessprobe.
# This is part of process to release binary artifacts to customers that need
# to create their own Dockerfile.
- name: build_binaries
  tags: ["release_operator"]
  patch_only: true
  commands:
    - func: clone
    - func: setup_jq
    - func: build_operator
    - func: build_database
      vars:
        distro: dcar
    - func: push_versioned_binaries

- name: build_test_image
  priority: 60
  type: setup
  commands:
  - func: clone
  - func: download_kube_tools
  - func: setup_aws
  - func: setup_kubernetes_environment
    vars:
      <<: *kubernetes_environment_openshift_3
  - func: upload_e2e_build_context
    vars:
      distro: scratch
      context: tests
  - func: kaniko_build
    vars:
      destination: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/mongodb-enterprise-tests:${version_id}
      context: s3://ops-manager-kubernetes-build/ops-manager-operator/${version_id}:scratch/contexts/tests-context.tar.gz
      cache_repo: 268558157000.dkr.ecr.us-east-1.amazonaws.com/cache/mongodb-enterprise-tests
      label: tests-${version_id}
  # kaniko_wait will block until all the Pods with 'labels' are in Succeeded state.
  - func: kaniko_wait
    vars:
      label: 'tests-${version_id}'

- name: build_images_rhel
  priority: 60
  type: setup
  commands:
  - func: clone
  - func: download_kube_tools
  - func: setup_ecr_login_helper
  - func: setup_jq
  - func: build_operator
    vars:
      distro: rhel
  - func: build_database
    vars:
      distro: rhel
  - func: upload_e2e_build_context
    vars:
      distro: rhel
      context: operator
  - func: setup_kubernetes_environment
    vars:
      <<: *kubernetes_environment_openshift_3
  - func: kaniko_build
    vars:
      destination: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/rhel/mongodb-enterprise-operator:${version_id}
      context: s3://ops-manager-kubernetes-build/ops-manager-operator/${version_id}:rhel/contexts/operator-context.tar.gz
      cache_repo: 268558157000.dkr.ecr.us-east-1.amazonaws.com/cache/mongodb-enterprise-operator
      label: rhel-operator-${version_id}
  - func: kaniko_build
    vars:
      destination: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/rhel/mongodb-enterprise-database:${version_id}
      context: s3://ops-manager-kubernetes-build/ops-manager-operator/${version_id}:rhel/contexts/database-context.tar.gz
      cache_repo: 268558157000.dkr.ecr.us-east-1.amazonaws.com/cache/mongodb-enterprise-database
      label: rhel-database-${version_id}
  - func: kaniko_wait
    vars:
      label: 'rhel-operator-${version_id}, rhel-database-${version_id}'

- name: build_images_ubuntu
  priority: 60
  commands:
  - func: clone
  - func: download_kube_tools
  - func: setup_ecr_login_helper
  - func: setup_jq
  - func: build_operator
    vars:
      distro: ubuntu
  - func: build_database
    vars:
      distro: ubuntu
  - func: upload_e2e_build_context
    vars:
      distro: ubuntu
      context: operator
  - func: setup_kubernetes_environment
    vars:
      <<: *kubernetes_environment_openshift_3
  - func: kaniko_build
    vars:
      destination: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-operator:${version_id}
      context: s3://ops-manager-kubernetes-build/ops-manager-operator/${version_id}:ubuntu/contexts/operator-context.tar.gz
      cache_repo: 268558157000.dkr.ecr.us-east-1.amazonaws.com/cache/mongodb-enterprise-operator
      label: ubuntu-operator-${version_id}
  - func: kaniko_build
    vars:
      destination: 268558157000.dkr.ecr.us-east-1.amazonaws.com/dev/ubuntu/mongodb-enterprise-database:${version_id}
      context: s3://ops-manager-kubernetes-build/ops-manager-operator/${version_id}:ubuntu/contexts/database-context.tar.gz
      cache_repo: 268558157000.dkr.ecr.us-east-1.amazonaws.com/cache/mongodb-enterprise-database
      label: ubuntu-database-${version_id}
  - func: kaniko_wait
    vars:
      label: 'ubuntu-operator-${version_id}, ubuntu-database-${version_id}'

- name: build_om_images_rhel
  priority: 60
  commands:
  - func: clone
  - func: setup_jq
  - func: setup_aws
  - func: setup_docker
  - func: build_operator
    vars:
      distro: rhel
  - func: build_and_push_om_test_images
    vars:
      cluster_type: "openshift"

- name: build_om_images_rhel_the_rest
  priority: 60
  commands:
  - func: clone
  - func: setup_jq
  - func: setup_aws
  - func: setup_docker
  - func: build_operator
    vars:
      distro: rhel
  - func: build_and_push_om_test_images_the_rest
    vars:
      cluster_type: "openshift"

- name: build_om_images_ubuntu
  commands:
  - func: clone
  - func: setup_jq
  - func: setup_aws
  - func: setup_docker
  - func: build_operator
    vars:
      distro: ubuntu
  - func: build_and_push_om_test_images
    vars:
      cluster_type: "kops"

- name: build_om_images_ubuntu_the_rest
  commands:
  - func: clone
  - func: setup_jq
  - func: setup_aws
  - func: setup_docker
  - func: build_operator
    vars:
      distro: ubuntu
  - func: build_and_push_om_test_images_the_rest
    vars:
      cluster_type: "kops"

- name: prepare_cluster_openshift_3
  exec_timeout_secs: 1200
  priority: 59
  commands:
    - func: clone
    - func: setup_aws
    - func: download_kube_tools
    - func: setup_kubernetes_environment
      vars:
        <<: *kubernetes_environment_openshift_3
    - func: prepare_test_env
      vars:
        <<: *ops_manager_42_current

- name: prepare_cluster_vanilla
  exec_timeout_secs: 1200
  priority: 59
  commands:
    - func: clone
    - func: setup_aws
    - func: download_kube_tools
    - func: setup_kubernetes_environment
      vars:
        <<: *kubernetes_environment_vanilla
    - func: prepare_test_env
      vars:
        <<: *ops_manager_40_first

    - func: prepare_test_env
      vars:
        <<: *ops_manager_42_current

- name: prepare_cluster_vanilla_om
  exec_timeout_secs: 600
  priority: 59
  commands:
    - func: clone
    - func: download_kube_tools
    - func: setup_aws
    - func: setup_kubernetes_environment
      vars:
        <<: *kubernetes_environment_vanilla
        cluster_name: e2e.om.mongokubernetes.com
    - func: prepare_test_env

- name: e2e_op_upgrade_one_deployment
  tags: ["patch-run"]
  exec_timeout_secs: 2400
  commands:
    - func: e2e_test
      vars:
        from_version: 1.2.2

- name: e2e_op_upgrade_replica_set
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: e2e_test
      vars:
        from_version: latest

- name: e2e_multiple_cluster_failures
  tags: ["patch-run"]
  commands:
    - func: e2e_test

- name: e2e_standalone_custom_podspec
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_standalone_schema_validation
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_schema_validation
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_schema_validation
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_users_schema_validation
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_standalone_config_map
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_standalone_groups
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_standalone_recovery
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_standalone_recovery_k8s
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_recovery
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_config_map
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_ent
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_groups
  tags: ["patch-run"]
  exec_timeout_secs: 600
  commands:
     - func: "e2e_test"

- name: e2e_replica_set_pv
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_pv_multiple
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_8_members
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_exposed_externally
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_readiness_probe
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_tls_sc_additional_certs
  tags: ["patch-run"]
  exec_timeout_secs: 720
  commands:
    - func: "e2e_test"

- name: e2e_tls_sc_additional_certs_transition
  tags: ["patch-run"]
  exec_timeout_secs: 720
  commands:
    - func: "e2e_test"

- name: e2e_tls_rs_additional_certs
  tags: ["patch-run"]
  exec_timeout_secs: 720
  commands:
    - func: "e2e_test"

- name: e2e_tls_rs_external_access
  tags: ["patch-run"]
  exec_timeout_secs: 900
  commands:
    - func: "e2e_test"

- name: e2e_tls_rs_external_access_tls_transition
  tags: ["patch-run"]
  exec_timeout_secs: 720
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_pv
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_recovery
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_secret
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_scale_shards
  tags: ["patch-run"]
  exec_timeout_secs: 720
  commands:
    - func: "e2e_test"

- name: e2e_standalone_type_change_recovery
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_all_mongodb_resources_parallel
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_standalone_upgrade_downgrade
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_upgrade_downgrade
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_custom_podspec
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_custom_podspec
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_upgrade_downgrade
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_standalone_no_tls_no_status_is_set
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_replica_set_tls_allow
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_replica_set_tls_prefer
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_replica_set_tls_require
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_replica_set_tls_require_custom_ca
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_sharded_cluster_tls_require_custom_ca
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_tls_x509_sc_custom_ca
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_replica_set_tls_require_and_disable # Broken
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_tls_multiple_different_ssl_configs
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_replica_set_tls_require_upgrade
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_sharded_cluster_tls_require
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
  - func: "e2e_test"

- name: e2e_tls_x509_rs
  tags: ["patch-run"]
  # longer timeout than usual as this test tests recovery from bad states which can take some time
  exec_timeout_secs: 1800
  commands:
  - func: "e2e_test"

- name: e2e_tls_x509_sc
  tags: ["openshift-om-42"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_tls_x509_users_addition_removal
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_tls_x509_user_connectivity
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_tls_x509_configure_all_options_rs
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_tls_x509_configure_all_options_sc
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_om_appdb_scale_up_down
  tags: ["patch-run"]
  exec_timeout_secs: 2400
  commands:
    - func: "e2e_test"

- name: e2e_om_appdb_upgrade
  tags: ["patch-run"]
  exec_timeout_secs: 2400
  commands:
  - func: "e2e_test"

- name: e2e_om_ops_manager_upgrade
  tags: ["patch-run"]
  exec_timeout_secs: 2400
  commands:
    - func: "e2e_test"

- name: e2e_om_external_connectivity
  tags: ["patch-run"]
  exec_timeout_secs: 2400
  commands:
    - func: "e2e_test"

- name: e2e_om_ops_manager_backup
  tags: ["patch-run"]
  exec_timeout_secs: 2400
  commands:
    - func: "e2e_test"

- name: e2e_om_appdb_validation
  tags: ["patch-run"]
  exec_timeout_secs: 600
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_scram_sha_256_user_connectivity
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_scram_sha_1_user_connectivity
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_scram_sha_256_user_connectivity
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_scram_sha_1_user_connectivity
  tags: ["patch-run"]
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_scram_sha_1_upgrade
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_scram_sha_1_upgrade
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_x509_to_scram_transition
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_x509_to_scram_transition
  tags: ["patch-run"]
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_replica_set_scram_sha_and_x509 # Broken
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_sharded_cluster_scram_sha_and_x509 # Broken
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_configure_tls_and_x509_simultaneously_rs
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

- name: e2e_configure_tls_and_x509_simultaneously_sc
  exec_timeout_secs: 1800
  commands:
    - func: "e2e_test"

- name: e2e_configure_tls_and_x509_simultaneously_st
  exec_timeout_secs: 1200
  commands:
    - func: "e2e_test"

# e2e_om_ops_manager_scale will not fit 3 OM images + 3 appdb on the same host
- name: e2e_om_ops_manager_scale
  exec_timeout_secs: 2800
  commands:
    - func: "e2e_test"

- name: e2e_om_appdb_scram
  tags: ["patch-run"]
  exec_timeout_secs: 2800
  commands:
    - func: "e2e_test"


task_groups:
- name: unit_task_group
  setup_group:
    - func: "clone"
  tasks:
    - unit_tests
    - unit_tests_lint

# This is the task group for Kubernetes-related e2e tests which focus on testing Kubernetes features instead of Automation Config
- name: e2e_kube_only_task_group
  max_hosts: 4
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_replica_set_config_map
    - e2e_replica_set_exposed_externally
    - e2e_replica_set_pv
    - e2e_replica_set_pv_multiple
    - e2e_replica_set_schema_validation
    - e2e_sharded_cluster_pv
    - e2e_sharded_cluster_recovery
    - e2e_sharded_cluster_schema_validation
    - e2e_standalone_config_map
    - e2e_standalone_recovery
    - e2e_standalone_recovery_k8s
    - e2e_standalone_schema_validation
    - e2e_users_schema_validation
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

  # This is the general task group which is supposed to be tested on ALL OM versions. Please don't add tests here which
  # don't test anything special in automation config and more focused on Kubernetes features - such tests should go to
  # 'e2e_kube_only_task_group' task group
- name: e2e_core_task_group
  max_hosts: 4
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_all_mongodb_resources_parallel
    - e2e_multiple_cluster_failures
    - e2e_op_upgrade_replica_set
    - e2e_op_upgrade_one_deployment
    - e2e_replica_set
    - e2e_replica_set_8_members
    - e2e_replica_set_ent
    - e2e_replica_set_groups
    - e2e_replica_set_recovery
    - e2e_replica_set_upgrade_downgrade
    - e2e_replica_set_custom_podspec
    - e2e_sharded_cluster
    - e2e_sharded_cluster_secret
    - e2e_sharded_cluster_upgrade_downgrade
    - e2e_sharded_cluster_custom_podspec
    - e2e_standalone_groups
    - e2e_standalone_type_change_recovery
    - e2e_standalone_upgrade_downgrade
    - e2e_standalone_custom_podspec
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

- name: e2e_tls_task_group
  max_hosts: 3
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_replica_set_tls_allow
    - e2e_replica_set_tls_prefer
    - e2e_replica_set_tls_require
    - e2e_replica_set_tls_require_upgrade
    - e2e_replica_set_tls_require_and_disable
    - e2e_tls_rs_additional_certs
    - e2e_tls_sc_additional_certs
    - e2e_tls_sc_additional_certs_transition
    - e2e_sharded_cluster_tls_require
    - e2e_standalone_no_tls_no_status_is_set
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

- name: e2e_scram_sha_task_group
  max_hosts: 3
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_replica_set_scram_sha_256_user_connectivity
    - e2e_replica_set_scram_sha_1_user_connectivity
    - e2e_replica_set_scram_sha_1_upgrade
    - e2e_replica_set_x509_to_scram_transition
    - e2e_replica_set_scram_sha_and_x509
    - e2e_sharded_cluster_scram_sha_1_upgrade
    - e2e_sharded_cluster_x509_to_scram_transition
    - e2e_sharded_cluster_scram_sha_256_user_connectivity
    - e2e_sharded_cluster_scram_sha_1_user_connectivity
    - e2e_sharded_cluster_scram_sha_and_x509
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

# e2e_tls_custom_ca_task_group tests if the operator works with custom
# certificate authorities. This is not run on patch builds.
- name: e2e_tls_custom_ca_task_group
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_replica_set_tls_require_custom_ca
    - e2e_sharded_cluster_tls_require_custom_ca
    - e2e_tls_x509_sc_custom_ca
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

# The "others" tasks are those which cannot be run on 4.0 - only on 4.2+
- name: e2e_om_4_2_plus_only_task_group
  max_hosts: 1
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_sharded_cluster_scale_shards
    - e2e_replica_set_readiness_probe
    - e2e_tls_rs_external_access
    - e2e_tls_rs_external_access_tls_transition
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

- name: e2e_x509_task_group
  max_hosts: 3
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_configure_tls_and_x509_simultaneously_st
    - e2e_configure_tls_and_x509_simultaneously_rs
    - e2e_configure_tls_and_x509_simultaneously_sc
    - e2e_tls_x509_rs
    - e2e_tls_x509_sc
    - e2e_tls_x509_configure_all_options_rs
    - e2e_tls_x509_configure_all_options_sc
    - e2e_tls_x509_user_connectivity
    - e2e_tls_x509_users_addition_removal
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

- name: e2e_ops_manager_task_group
  max_hosts: 3
  setup_group:
    - func: clone
    - func: download_kube_tools
  setup_task:
    - func: setup_kubernetes_environment
    - func: setup_cloud_qa
  tasks:
    - e2e_om_appdb_scale_up_down
    - e2e_om_appdb_upgrade
    - e2e_om_appdb_validation
    - e2e_om_appdb_scram
    - e2e_om_ops_manager_backup
    - e2e_om_ops_manager_scale
    - e2e_om_ops_manager_upgrade
    - e2e_om_external_connectivity
  teardown_task:
    - func: upload_e2e_logs
    - func: teardown_kubernetes_environment
    - func: teardown_cloud_qa

buildvariants:
- name: e2e_kube_vanilla_om_40_first
  display_name: "e2e_kube_vanilla_om_40_first"
  depends_on:
    - name: build_images_ubuntu
      variant: init_test_run
    - name: build_test_image
      variant: init_test_run
    - name: prepare_cluster_vanilla
      variant: init_test_run
  run_on:
  - archlinux-test
  stepback: false
  expansions:
    <<: *ops_manager_40_first
    <<: *kubernetes_environment_vanilla
    distro: ubuntu
  tasks:
  - name: "e2e_core_task_group"
  - name: "e2e_tls_task_group"

# Note that both kops (current build variant) and openshift (next build variant) work with the same version of OM
# so in general they shouldn't intersect on OM-related tasks. Currently they intersect only on 'e2e_kube_only_task_group'
# and 'e2e_om_4_2_plus_only_task_group' as the latter must be run on both kops and openshift
- name: e2e_kube_vanilla_om_42_current
  display_name: "e2e_kube_vanilla_om_42_current"
  depends_on:
    - name: build_images_ubuntu
      variant: init_test_run
    - name: build_test_image
      variant: init_test_run
    - name: prepare_cluster_vanilla
      variant: init_test_run
  run_on:
  - archlinux-test
  stepback: false
  expansions:
    <<: *ops_manager_42_current
    <<: *kubernetes_environment_vanilla
    distro: ubuntu
  tasks:
  - name: "e2e_kube_only_task_group"
  - name: "e2e_om_4_2_plus_only_task_group"
  - name: "e2e_tls_task_group"
  - name: "e2e_scram_sha_task_group"
  - name: "e2e_x509_task_group"

- name: e2e_openshift_origin_v3_om_42_current
  display_name: "e2e_openshift_origin_v3_om_42_current"
  depends_on:
    - name: build_images_rhel
      variant: init_test_run
    - name: build_test_image
      variant: init_test_run
    - name: prepare_cluster_openshift_3
      variant: init_test_run
  run_on:
  - archlinux-test
  stepback: false
  expansions:
    <<: *ops_manager_42_current
    <<: *kubernetes_environment_openshift_3
    distro: rhel
  tasks:
    # Before adding the task / task_group to the current build variant check the comment on the previous one
    # ('e2e_kube_vanilla_om_42_current')
  - name: "e2e_kube_only_task_group"
  - name: "e2e_om_4_2_plus_only_task_group"
  - name: "e2e_core_task_group"
  - name: "e2e_tls_custom_ca_task_group"

- name: e2e_openshift_cloud_qa
  display_name: "e2e_openshift_cloud_qa"
  depends_on:
    - name: build_images_rhel
      variant: init_test_run
    - name: build_test_image
      variant: init_test_run
  run_on:
  - archlinux-test
  stepback: false
  expansions:
    <<: *cloud_manager_qa
    <<: *kubernetes_environment_openshift_3
    distro: rhel
  tasks:
  - name: "e2e_core_task_group"
  - name: "e2e_tls_task_group"
  - name: "e2e_x509_task_group"
  - name: "e2e_tls_custom_ca_task_group"
  - name: "e2e_scram_sha_task_group"

- name: e2e_kube_vanilla_ops_manager
  display_name: "e2e_kube_vanilla_ops_manager"
  depends_on:
    - name: build_images_ubuntu
      variant: init_test_run
    - name: build_test_image
      variant: init_test_run
    - name: build_om_images_ubuntu
      variant: init_test_run
    - name: build_om_images_ubuntu_the_rest
      variant: init_test_run
    - name: prepare_cluster_vanilla_om
      variant: init_test_run
  run_on:
    - archlinux-test
  stepback: false
  expansions:
    cluster_name: "e2e.om.mongokubernetes.com"
    <<: *kubernetes_environment_vanilla
    test_mode: "opsmanager"
    distro: ubuntu
  tasks:
    - name: "e2e_ops_manager_task_group"

- name: e2e_openshift_origin_v3_ops_manager
  display_name: e2e_openshift_origin_v3_ops_manager
  depends_on:
    - name: build_images_rhel
      variant: init_test_run
    - name: build_test_image
      variant: init_test_run
    - name: build_om_images_rhel
      variant: init_test_run
    - name: build_om_images_rhel_the_rest
      variant: init_test_run
    - name: prepare_cluster_openshift_3
      variant: init_test_run
  run_on:
    - archlinux-test
  stepback: false
  expansions:
    <<: *ops_manager_42_current
    <<: *kubernetes_environment_openshift_3
    test_mode: opsmanager
    distro: rhel
  tasks:
    - name: "e2e_ops_manager_task_group"

- name: release_rh_connect
  display_name: release_rh_connect
  depends_on:
    - name: release_blocker
      variant: release_blocker
  run_on:
    - archlinux-test
  expansions:
    docker_registry: scan.connect.redhat.com
    docker_username: unused
  tasks:
    - name: release_ops_manager_rh_connect
    - name: release_operator_rh_connect

- name: release_quay
  display_name: release_quay
  depends_on:
    - name: release_blocker
      variant: release_blocker
  run_on:
    - archlinux-test
  expansions:
    docker_registry: quay.io
  tasks:
    - name: release_ops_manager_quay
    - name: release_operator_quay

- name: release_blocker
  display_name: release_blocker
  run_on:
  - ubuntu1604-packer  # Note: cheapest machine I found
  tasks:
  - name: release_blocker

- name: init_test_run
  display_name: init_test_run
  run_on:
  - archlinux-test
  stepback: false
  tasks:
  - name: build_images_rhel
  - name: build_images_ubuntu
  - name: build_test_image
  - name: build_om_images_ubuntu
  - name: build_om_images_ubuntu_the_rest
  - name: build_om_images_rhel
  - name: build_om_images_rhel_the_rest
  - name: prepare_cluster_openshift_3
  - name: prepare_cluster_vanilla
  - name: prepare_cluster_vanilla_om

# Runs on master patches. This will populate the mongodb/mongodb-enterprise-*-prerelease
# registries with the images that were pushed to master
- name: prerelease_master_images
  display_name: prerelease_master_images
  run_on:
  - ubuntu1604-test
  depends_on:
  - name: build_images_ubuntu
    variant: init_test_run
  - name: build_om_images_ubuntu
    variant: init_test_run
  - name: build_om_images_ubuntu_the_rest
    variant: init_test_run
  expansions:
    docker_registry: quay.io
  tasks:
  - name: prerelease_master_images

- name: go_unit_tests
  display_name: "go_unit_tests"
  run_on:
  - archlinux-test
  stepback: false
  tasks:
    - name: "unit_task_group"

# Isolated Ops Manager Tests
- name: e2e_kind_ops_manager
  display_name: e2e_kind_ops_manager
  run_on:
  - ubuntu1604-build
  depends_on:
  - name: build_images_rhel
    variant: init_test_run
  - name: build_test_image
    variant: init_test_run
  - name: build_om_images_rhel
    variant: init_test_run
  expansions:
    <<: *kubernetes_environment_kind
    distro: rhel
    test_mode: opsmanager
  tasks:
  - name: e2e_ops_manager_task_group

- name: e2e_kind_cloud_qa
  display_name: e2e_kind_cloud_qa
  run_on:
  - ubuntu1604-build
  depends_on:
  - name: build_images_ubuntu
    variant: init_test_run
  - name: build_test_image
    variant: init_test_run
  expansions:
    <<: *cloud_manager_qa
    <<: *kubernetes_environment_kind
    distro: ubuntu
  tasks:
  - name: e2e_kube_only_task_group
  - name: e2e_core_task_group
  - name: e2e_tls_task_group
  - name: e2e_om_4_2_plus_only_task_group
  - name: e2e_x509_task_group
  - name: e2e_scram_sha_task_group
