#!/usr/bin/env bash

set -euo pipefail

KUBECONFIG_SAVED="${KUBECONFIG}"
unset KUBECONFIG

# Make sure kubectl fails if no KUBECONFIG is set
if kubectl get nodes &> /dev/null; then
    echo "There's a kubectl context defined globally ($HOME/.kube/config exists)"
    exit 1
fi

KUBECONFIG="${KUBECONFIG_SAVED}"
export KUBECONFIG

# This trick comes from https://stackoverflow.com/a/4774063/222470
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
cd "$(${DIR}/../gitroot)"

source scripts/funcs/kubernetes

##
## Does some preliminary actions to prepare testing environment:
## - fixes AWS
## - installs cluster cleaner
## - starts Ops Manager if it's not started yet and if it's necessary
##

# cleanup_env fixes AWS problems if any
fix_env() {
    ns_count="$(kubectl get ns -o name | grep a- --count || true)"
    echo "Current number of test namespaces: $ns_count"

    # sometimes in kops cluster some nodes get this taint that makes nodes non-schedulable. Just going over all nodes and
    # trying to remove the taint is supposed to help
    echo "##### Fixing taints"
    for n in $(kubectl get nodes -o name); do
        kubectl taint nodes "${n}" NodeWithImpairedVolumes:NoSchedule- 2> /dev/null || true
    done

    echo "##### Removing FAILED Persistent Volumes if any"
    # Note, that these volumes will be removed from EBS eventually (during a couple of hours), most of all they are stuck
    # in attaching - this results in nodes getting taints "NoSchedule"
    for v in $(kubectl get pv -o=custom-columns=NAME:.metadata.name,status:.status.phase | grep Failed | awk '{ print $1 }'); do
        kubectl delete pv ${v}
    done

    echo "##### Detaching the EBS Volumes that are stuck"
    for v in $(aws ec2 describe-volumes --filters Name=attachment.status,Values=attaching | grep VolumeId | cut -d "\"" -f 4); do
        set -v
        aws ec2 detach-volume --volume-id ${v} --force || true
        set +v
    done

    echo "##### Removing ESB volumes which are not used any more"
    # Seems Openshift (sometimes?) doesn't remove the volumes but marks them as available - we need to clean these volumes
    # manually
    for v in $(aws ec2 describe-volumes --filters Name=status,Values=available | grep VolumeId | cut -d "\"" -f 4); do
        set -v
        aws ec2 delete-volume --volume-id ${v} || true
        set +v
    done

    echo "##### Removing old s3 buckets"
    # note, to run this on mac you need to install coreutils ('brew install coreutils') and use 'gdate' instead
    yesterday=$(date +%Y-%m-%d -d "yesterday")
    for bucket in $(aws s3api list-buckets --query 'Buckets[?CreationDate<=`'$yesterday'`&&contains(Name,`test-bucket-`)]' | jq --raw-output '.[].Name'); do
        aws s3 rb s3://$bucket --force
    done

}

# The functions checks the size for the ECR repository and recreates it if necessary
# This may affect some parallel running tests, so should be called quite rarely - when the size exceeds 500
# (note, that 'aws ecr list-images' for some reasons returns the ~700+ images when in fact there are 1000 of them -
# so we choose 500 as a some representative number)
check_and_clean_repo() {
    if [[ $(aws ecr list-images --repository-name "$1" | grep -c imageDigest) -gt 500 ]]; then
        echo "Recreating the \"$1\" repo"
        aws ecr delete-repository --repository-name "$1" --force
        aws ecr create-repository --repository-name "$1"
    fi
}

deploy_cluster_cleaner() {
    ops_manager_namespace="${1}"
    cleaner_namespace="cluster-cleaner"
    if ! kubectl get "ns/${cleaner_namespace=}" &> /dev/null ; then
        kubectl create namespace "${cleaner_namespace=}"
    fi

    if [[ -n "${ops_manager_namespace}" ]]; then
        kubectl create namespace "${ops_manager_namespace}" || true
    fi

    helm template docker/cluster-cleaner \
         --set cleanerVersion=latest \
         --set namespace="${ops_manager_namespace}" \
         --set cleanerNamespace=cluster-cleaner \
         > cluster-cleaner.yaml
    kubectl apply -f cluster-cleaner.yaml
    rm cluster-cleaner.yaml
}

ops_manager_namespace="${1:-}"
ops_manager_version="${2:-}"
node_port="${3:-}"

echo "Fixing AWS problems if any"
fix_env

echo "Deploying cluster-cleaner"
deploy_cluster_cleaner "${ops_manager_namespace}"

if [[ "${OM_EXTERNALLY_CONFIGURED:-}" != "true" ]] && [[ -n "${ops_manager_namespace}" ]]; then
    ensure_ops_manager_k8s "${ops_manager_namespace}" "${ops_manager_version}" "${node_port}"
fi
