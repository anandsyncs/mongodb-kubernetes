#!/usr/bin/env bash

set -Eeou pipefail

pushd "$PWD" > /dev/null || return
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
cd "$DIR" || return
# shellcheck source=scripts/funcs/checks
source checks
# shellcheck source=scripts/funcs/errors
source errors
# shellcheck source=scripts/funcs/printing
source printing
popd > /dev/null || return

ensure_namespace() {
    local namespace="${1}"
    local tmp_file
    tmp_file=$(mktemp)
    cat <<EOF > "${tmp_file}"
apiVersion: v1
kind: Namespace
metadata:
  name: ${namespace}
  labels:
    evg: task
  annotations:
    evg/version: "https://evergreen.mongodb.com/version/${version_id:-'not-specified'}"
    evg/task-name: ${TASK_NAME:-'not-specified'}
    evg/task: "https://evergreen.mongodb.com/task/${TASK_ID:-'not-specified'}"
    evg/mms-version: "${MMS_VERSION:-'not-specified'}"
EOF

    if kubectl get "ns/${namespace}" -o name &> /dev/null; then
        echo "Namespace ${namespace} already exists!"
    else
        echo "Creating new namespace: ${namespace}"
        cat "${tmp_file}"
        kubectl create -f "${tmp_file}"
    fi
}

# the function installs Ops Manager (legacy dev version) into Kubernetes cluster if it's not installed already
# Note, that this requires the k8s node with 4 Gb of free memory
ensure_ops_manager_k8s() {
    local ops_manager_namespace="${1}"
    local ops_manager_version="${2}"
    local node_port="${3}"

    if [ -z "${ops_manager_namespace}" ]; then
        error "ops_manager_namespace must be set!"
        exit 1
    fi
    if [ -z "${ops_manager_version}" ]; then
        error "ops_manager_version must be set!"
        exit 1
    fi
    if [ -z "${node_port}" ]; then
        error "node_port must be set!"
        exit 1
    fi

    echo "##### Installing Ops Manager ${ops_manager_version} (namespace ${ops_manager_namespace} into Kubernetes..."

    if _is_ops_manager_down "${ops_manager_namespace}"; then
        echo "Ops Manager is not installed in this cluster. Doing it now."
        echo "Run \"make -C docker/mongodb-enterprise-ops-manager-dev IMAGE_VERSION=${ops_manager_version} push\" to update Ops Manager image in ECR if necessary"

        echo "Installing Ops Manager ${ops_manager_version}"

        helm template -f scripts/evergreen/deployments/values-ops-manager.yaml \
            --set namespace="${ops_manager_namespace}" \
            --set opsManager.version="${ops_manager_version}" \
            --set opsManager.host="ops-manager.${ops_manager_namespace}.svc.cluster.local" \
            --set opsManager.nodePort="${node_port}" \
            docker/mongodb-enterprise-ops-manager-dev/helm_chart > mongodb-enterprise-ops-manager.yaml

        echo

        kubectl delete -f mongodb-enterprise-ops-manager.yaml || true
        kubectl apply -f mongodb-enterprise-ops-manager.yaml

        rm mongodb-enterprise-ops-manager.yaml

        echo "Waiting until Statefulset for Ops Manager is running..."

        local cmd
        # shellcheck disable=SC2016
        cmd='while [[ $(kubectl -n '${ops_manager_namespace}' get statefulset mongodb-enterprise-ops-manager -o jsonpath="{.status.currentReplicas}") != "1" ]]; do sleep 1; done'
        timeout "1m" bash -c "${cmd}" || true

        echo "Statefulset is ready, waiting for Ops Manager to start..."

        # We can't communicate with Ops Manager if it is inside Kubernetes, so we just
        # wait for this command to succeed.
        # Note, that for OM check for "status.phase==Running" may not work - we need to check the container status
        local cmd
        cmd="while ! kubectl get pod/mongodb-enterprise-ops-manager-0 -o jsonpath=\"{.status.containerStatuses[0].ready}\" -n ${ops_manager_namespace} | grep -q \"true\"; do sleep 4; done"
        timeout "10m" bash -c "${cmd}" || true

        if ! kubectl get pod/mongodb-enterprise-ops-manager-0 -o jsonpath="{.status.containerStatuses[0].ready}" -n "${ops_manager_namespace}" | grep -q "true"; then
            error "Ops Manager hasn't started!"
            kubectl describe pod/mongodb-enterprise-ops-manager-0 -n "${ops_manager_namespace}"
            exit 1
        fi
        echo "Pod is ready, waiting for the admin to get registered..."

        local cmd
        cmd="while ! kubectl -n ${ops_manager_namespace} exec mongodb-enterprise-ops-manager-0 ls \"/opt/mongodb/mms/env/.ops-manager-env\" &>/dev/null; do sleep 2; done"
        timeout "4m" bash -c "${cmd}" || true

        if ! kubectl -n "${ops_manager_namespace}" exec mongodb-enterprise-ops-manager-0 ls "/opt/mongodb/mms/env/.ops-manager-env" &>/dev/null; then
            error "No env file found in Ops Manager!"
            # todo print logs when OM image is fixed and rebuilt
            # kubectl logs  -n operator-testing mongodb-enterprise-ops-manager-0

            exit 1
        fi

        # we try to open ports for both security groups - in kops and openshift clusters
        _ensure_vpc_rules "us-east-2" "nodes.e2e"

        echo "Ops Manager is installed in this cluster. A new user will be added for automated tests to run."
    else
        echo "Ops Manager is already installed in this cluster."
        echo "If you want to start with a fresh Ops Manager installation, please delete the \"${ops_manager_namespace}\" namespace."
    fi

    echo "##### Ops Manager is ready"

    _print_om_endpoint "" "${ops_manager_namespace}" "${node_port}"
}

_print_om_endpoint() {
    local ops_manager_namespace="${2}"
    if [ -z "$ops_manager_namespace" ]; then
        error "No ops_manager_namespace set: not able to find Ops Manager external IP"
    else
        local node_port="${3}"
        local node_name
        node_name=$(kubectl get pods/mongodb-enterprise-ops-manager-0 -n "${ops_manager_namespace}" -o wide | tail -n 1 | awk '{print $7}')
        local external_ip
        external_ip="$(kubectl get nodes -o wide | grep "${node_name}" | awk '{print $7}')"

        echo "Use the following address to access Ops Manager from the browser: http://${external_ip}:${node_port}"
    fi
}

_ensure_vpc_rules() {
    local region="$1"
    local prefix="$2"
    local group_id
    group_id=$(aws ec2 describe-security-groups --region "${region}" | jq -r '.SecurityGroups[] | select(.GroupName | startswith( "'"$prefix"'")) | .GroupId')

    if [[ -z $group_id ]]; then
        echo "Failed to find group id for EC2 security group with prefix $prefix"
        return 1
    fi
    # note, that the attempt to add the same rule will result in "already exists" error - so we just ignore errors by now
    # open multiple node ports for different versions of Ops Manager
    for i in $(seq 30039 30043); do
        aws ec2 authorize-security-group-ingress --region "${region}" --group-id "${group_id}" --protocol tcp --port "${i}" --cidr "0.0.0.0/0" 2>/dev/null || true
        echo "Opened port ${i} in AWS for the security group with prefix $prefix (group id: $group_id)"
    done

}
# returns true if the namespace doesn't exist or if the OM pod is not running and this lasts for more than or equal to 1 hour.
# This is supposed to work for concurrent builds when one of the builds is starting Ops Manager (ideally we need to check for 10 minutes
# but parsing dates in bash is hard :( )
_is_ops_manager_down() {
    ! kubectl get "namespace/${1}" &> /dev/null || \
    ! kubectl get pod/mongodb-enterprise-ops-manager-0 -n "${1}" 2>/dev/null ||
    kubectl get pod/mongodb-enterprise-ops-manager-0 -o jsonpath="{.status.containerStatuses[0].ready}" -n "${1}" | grep -q "false"

}

delete_operator() {
    local ns="$1"
    local name=${OPERATOR_NAME:=mongodb-enterprise-operator}

    title "Removing the Operator deployment ${name}"
    ! kubectl --namespace "${ns}" get deployments | grep -q ${name} \
        || kubectl delete deployment $name -n "${ns}"
}

# Generates kube yaml configuration for the Operator from helm chart and deletes + installs the Operator to the Kubernetes cluster
deploy_operator() {
    local registry_url="$1"
    local init_om_registry="$2"
    local init_appdb_registry="$3"
    local ns="$4"
    # optional fields
    local version="${5:-latest}"
    local watch_namespace="${6:-$ns}"
    local pull_policy="${7:-Always}"
    local managed_security_context="${8:-false}"
    local om_repository="${9:-quay.io/mongodb}"
    local appdb_repository="${10:-quay.io/mongodb}"

    # should we pass init_om_version to the script to avoid having evg env variable leak in here?
    [[ -z "${init_om_version:-}" ]] && init_om_version="${version_id:-latest}"

    [[ -z "${init_appdb_version:-}" ]] && init_appdb_version="${version_id:-latest}"

    title "Installing the Operator (registry url: ${registry_url}, ops_manager registry: ${om_repository}, init_ops_manager registry: ${init_om_registry}, init_ops_manager version: ${init_om_version}, appdb registry: ${appdb_repository}, init_appdb registry: ${init_appdb_registry}, init_appdb version: ${init_appdb_version}, version: ${version}, namespace: ${ns}, managed_security_context: ${managed_security_context}), debug: ${DEBUG-}) to ${CLUSTER_NAME:-'e2e cluster'}..."

    check_app "helm" "helm is not installed, run 'make prerequisites' to install all necessary software"
    check_app "timeout" "coreutils is not installed, call \"brew install coreutils\""

    local tmp_file
    tmp_file=$(mktemp)

    local helm_params
    helm_params=(
         "--set" "registry.operator=${registry_url}"
         "--set" "registry.opsManager=${om_repository}"
         "--set" "registry.initOpsManager=${init_om_registry}"
         "--set" "registry.initOpsManager=${init_om_registry}"
         "--set" "registry.appDb=${appdb_repository}"
         "--set" "registry.initAppDb=${init_appdb_registry}"
         "--set" "registry.pullPolicy=${pull_policy}"
         "--set" "operator.env=dev"
         "--set" "operator.version=${version}"
         "--set" "operator.watchNamespace=${watch_namespace}"
         "--set" "operator.name=${OPERATOR_NAME:=mongodb-enterprise-operator}"
         "--set" "database.name=${DATABASE_NAME:=mongodb-enterprise-database}"
         "--set" "opsManager.name=${OPS_MANAGER_NAME:=mongodb-enterprise-ops-manager}"
         "--set" "initOpsManager.name=${INIT_OPS_MANAGER_NAME:=mongodb-enterprise-init-ops-manager}"
         "--set" "initOpsManager.version=${init_om_version}"
         "--set" "initAppDb.name=${INIT_APPDB_NAME:=mongodb-enterprise-init-appdb}"
         "--set" "initAppDb.version=${init_appdb_version}"
         "--set" "appDb.name=${APPDB_NAME:=mongodb-enterprise-appdb}"
         "--set" "namespace=${ns}"
         "--set" "managedSecurityContext=${managed_security_context}"
         "--set" "debug=${DEBUG-}"
         "--set" "debugPort=${DEBUG_PORT:-30042}"
    )

    if [[ -n "${ecr_registry_needs_auth-}" ]]; then
        echo "Configuring imagePullSecrets to ${ecr_registry_needs_auth}"
        helm_params+=("--set" "registry.imagePullSecrets=${ecr_registry_needs_auth}")
    fi

    chart_path="public/helm_chart"
    # this script may be run from public github repo - there's no "public" folder
    [[ -d "helm_chart" ]] && chart_path="helm_chart"
    helm template "${chart_path}" "${helm_params[@]}"> "${tmp_file}"

    echo "Deploying Operator"
    kubectl apply -f "${tmp_file}"
    rm "${tmp_file}"
}

# wait_for_operator waits for the Operator to start
wait_for_operator_start() {
    local ns="$1"
    local timeout="${2:-2m}"
    echo "Waiting until the Operator gets to Running state..."
    export OPERATOR_NAME

    local cmd

    # Waiting until there is only one pod left as this could be the upgrade operation (very fast in practice)
    # shellcheck disable=SC2016
    cmd='while [[ $(kubectl -n '"${ns}"' get pods -l app=${OPERATOR_NAME}  --no-headers 2>/dev/null | wc -l) -gt 1 ]] ; do printf .; sleep 1; done'
    timeout --foreground "1m" bash -c "${cmd}" || true

    cmd="while ! kubectl -n ${ns} get pods -l app=${OPERATOR_NAME} -o jsonpath={.items[0].status.phase} 2>/dev/null | grep -q Running ; do printf .; sleep 1; done"
    timeout --foreground "${timeout}" bash -c "${cmd}" || true

    # In the end let's check again and print the state
    if ! kubectl -n "${ns}" get pods -l "app=${OPERATOR_NAME}" -o jsonpath="{.items[0].status.phase}" | grep -q "Running"; then
        error "Operator hasn't reached RUNNING state after ${timeout}. The full yaml configuration for the pod is:"
        kubectl -n "${ns}" get pods -l "app=${OPERATOR_NAME}" -o yaml

        title "Operator failed to start, exiting"
        return 1
    fi
    echo ""

    title "The Operator successfully installed to the Kubernetes cluster"
}

# Creates kops cluster and adds the support for dashboard
create_kops_cluster() {
    local cluster_name="${1}"
    local node_count=${2}
    local node_volume_size=${3}
    local node_size="${4}"
    local master_size="${5}"
    local zones="${6}"

    title "Creating kops cluster $cluster_name (master: $master_size, nodes: $master_size, zones: $zones)"

    check_env_var "KOPS_STATE_STORE" "Make sure you add \"export KOPS_STATE_STORE=s3://kube-om-state-store\" to your ~/.bashrc"

    echo "Make sure you use the latest version of kops (>= 1.14.0): 'brew upgrade kops'"
    kops create cluster \
         --node-count "$node_count" \
         --zones "${zones}" \
         --node-size "${node_size}" \
         --node-volume-size "${node_volume_size}" \
         --master-size="${master_size}" \
         --master-volume-size 16  \
         --kubernetes-version=v1.15.10 \
         --ssh-public-key=~/.ssh/id_rsa.pub \
         --authorization RBAC "${cluster_name}"

    kops create secret --name "${cluster_name}" sshpublickey admin -i ~/.ssh/id_rsa.pub

    kops update cluster "${cluster_name}" --yes

    echo "Waiting until kops cluster gets ready..."

    local cmd
    cmd="while ! kops validate cluster ${cluster_name} &>/dev/null ; do printf .; sleep 5; done"
    timeout "20m" bash -c "${cmd}"

    title "Kops cluster ${cluster_name} is ready! Note, that you need to use 'admin' user if you want to ssh to the nodes"

    # see https://codeandunicorns.com/kubernetes-dashboard-kops/
    # also keep an eye on https://github.com/kubernetes/dashboard/releases - we should use 2.0.0 once it goes to GA
    title "Adding support for Kubernetes dashboard"
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml

    #To create a service account with access to default namespace
    kubectl create serviceaccount dashboard -n default

    #To create a cluster role bind. Connecting service account and cluster level access
    kubectl create clusterrolebinding dashboard-admin -n default \
     --clusterrole=cluster-admin \
     --serviceaccount=default:dashboard

    title "Kubernetes dashboard is installed, use \"make dashboard\" to open it"
}

# Makes sure the ECR repository exists.
# The incoming parameter is expected to be the full ECR url (e.g. "268558157000.dkr.ecr.us-east-1.amazonaws.com/alis/ubuntu/mongodb-enterprise-appdb")
ensure_ecr_repository() {
    local repo_url=$1
    local repo_name

    if [[ ${REPO_TYPE} = "ecr" ]]; then
        repo_name="$(echo "${repo_url}" | cut -d "/" -f2-)" # "alis/ubuntu/mongodb-enterprise-appdb"
        if ! aws ecr describe-repositories | grep "${repo_name}" > /dev/null; then
            echo "Creating repository ${repo_name} as it doesn't exist"
            aws ecr create-repository --repository-name="${repo_name}"
        fi
    fi
}
